{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88760284",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2388479617.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    In a simple linear regression model, we aim to describe the relationship between a predictor (independent variable) \\( x \\) and an outcome (dependent variable) \\( Y \\). The model assumes that each observed outcome \\( Y \\) can be predicted by a linear equation:\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "In a simple linear regression model, we aim to describe the relationship between a predictor (independent variable) \\( x \\) and an outcome (dependent variable) \\( Y \\). The model assumes that each observed outcome \\( Y \\) can be predicted by a linear equation:\n",
    "\n",
    "\\[\n",
    "Y = \\beta_0 + \\beta_1 x + \\epsilon\n",
    "\\]\n",
    "\n",
    "where:\n",
    "- \\( \\beta_0 \\) (intercept) is the starting value of \\( Y \\) when \\( x \\) is zero.\n",
    "- \\( \\beta_1 \\) (slope) represents the change in \\( Y \\) for a one-unit change in \\( x \\).\n",
    "- \\( \\epsilon \\) (error term) captures the random variation in \\( Y \\) that isn’t explained by the linear relationship with \\( x \\).\n",
    "\n",
    "In this theoretical model, the predictor \\( x \\) values are often fixed or chosen arbitrarily, while the error term \\( \\epsilon \\) is usually sampled from a normal distribution with mean 0 and a chosen standard deviation \\( \\sigma \\). The assumption of normality in \\( \\epsilon \\) implies that for a fixed \\( x \\), the distribution of \\( Y \\) values around the line \\( \\beta_0 + \\beta_1 x \\) follows a normal distribution centered around the linear prediction.\n",
    "\n",
    "Here's a code example in Python using `numpy` and `scipy.stats` to simulate data based on this theoretical model.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import norm, uniform\n",
    "\n",
    "# Parameters for the simple linear model\n",
    "n = 100  # number of observations\n",
    "beta0 = 5  # intercept\n",
    "beta1 = 2  # slope\n",
    "sigma = 1  # standard deviation of the error term\n",
    "\n",
    "# Generate predictor values (x) from a uniform distribution\n",
    "x = uniform.rvs(0, 10, size=n)\n",
    "\n",
    "# Generate error terms (epsilon) from a normal distribution\n",
    "epsilon = norm.rvs(0, sigma, size=n)\n",
    "\n",
    "# Calculate the outcome values (Y) based on the theoretical model\n",
    "Y = beta0 + beta1 * x + epsilon\n",
    "\n",
    "# Visualization using plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add scatter plot for the generated data\n",
    "fig.add_trace(go.Scatter(x=x, y=Y, mode='markers', name='Data'))\n",
    "\n",
    "# Add the theoretical line (Y = beta0 + beta1 * x)\n",
    "x_line = np.linspace(min(x), max(x), 100)\n",
    "y_line = beta0 + beta1 * x_line\n",
    "fig.add_trace(go.Scatter(x=x_line, y=y_line, mode='lines', name='Theoretical Line'))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"Theoretical Simple Linear Regression Model\",\n",
    "    xaxis_title=\"Predictor (x)\",\n",
    "    yaxis_title=\"Outcome (Y)\"\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "### Summary\n",
    "\n",
    "This code simulates a theoretical simple linear regression model by:\n",
    "1. Setting fixed parameters for the intercept and slope.\n",
    "2. Generating predictor values \\( x \\) from a uniform distribution.\n",
    "3. Adding normally distributed errors \\( \\epsilon \\) to introduce random variation around the theoretical line.\n",
    "4. Creating a plot of the simulated data points and the theoretical line, visually showing how \\( Y \\) values are distributed around the linear relationship defined by the model. \n",
    "\n",
    "This model specification focuses on generating data rather than fitting a line to existing data, as it simulates how observed outcomes might arise from a theoretical linear relationship with an error term.\n",
    "https://chatgpt.com/share/672cb366-21c8-800d-b3e6-4dc37f39c529"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc735260",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1094869562.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    1. **`import statsmodels.formula.api as smf`**\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "### Explanation of Libraries and Steps\n",
    "\n",
    "1. **`import statsmodels.formula.api as smf`**  \n",
    "   - This library provides tools for specifying and fitting statistical models using formulas, specifically ordinary least squares (OLS) for linear regression models. It allows us to define a model directly in terms of a formula like `\"Y ~ x\"`, which automatically understands that \\( Y \\) is the dependent variable and \\( x \\) is the predictor.\n",
    "\n",
    "2. **Data Preparation and Fitting**  \n",
    "   - We’ll first create a DataFrame `df` with our simulated data, with columns \"x\" and \"Y\".\n",
    "\n",
    "3. **Creating and Fitting the Model**\n",
    "   ```python\n",
    "   model_data_specification = smf.ols(\"Y ~ x\", data=df)\n",
    "   ```\n",
    "   - This line specifies the OLS model using the formula `\"Y ~ x\"`, indicating a linear model with \\( Y \\) as the outcome and \\( x \\) as the predictor, and it will use the data in `df`.\n",
    "\n",
    "   ```python\n",
    "   fitted_model = model_data_specification.fit()\n",
    "   ```\n",
    "   - This line fits the specified model to the data, calculating estimates for the intercept and slope that best fit the observed data.\n",
    "\n",
    "4. **Understanding Model Outputs**\n",
    "   - `fitted_model.summary()`: Provides a full statistical summary of the fitted model, including information on coefficients, significance levels, R-squared, and diagnostics.\n",
    "   - `fitted_model.summary().tables[1]`: Displays a concise table with coefficient estimates, standard errors, t-values, and p-values for each term (intercept and slope) in the model.\n",
    "   - `fitted_model.params`: Returns the estimated values of the model parameters (intercept and slope).\n",
    "   - `fitted_model.params.values`: Outputs the parameter values as an array, which is sometimes useful for calculations.\n",
    "   - `fitted_model.rsquared`: Returns the R-squared value, which is a measure of how well the model explains the variation in the outcome \\( Y \\).\n",
    "\n",
    "5. **Visualization of Fitted Model**\n",
    "   - Adding a trendline with `trendline='ols'` in `px.scatter()` creates and plots the OLS-fitted line. Alternatively, we can manually plot the fitted values as shown in `fig.add_scatter()` for more control.\n",
    "\n",
    "Here's the complete code:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import norm, uniform\n",
    "\n",
    "# Parameters for the simple linear model\n",
    "n = 100  # number of observations\n",
    "beta0 = 5  # intercept\n",
    "beta1 = 2  # slope\n",
    "sigma = 1  # standard deviation of the error term\n",
    "\n",
    "# Generate predictor values (x) from a uniform distribution\n",
    "x = uniform.rvs(0, 10, size=n)\n",
    "\n",
    "# Generate error terms (epsilon) from a normal distribution\n",
    "epsilon = norm.rvs(0, sigma, size=n)\n",
    "\n",
    "# Calculate the outcome values (Y) based on the theoretical model\n",
    "Y = beta0 + beta1 * x + epsilon\n",
    "\n",
    "# Combine into a pandas DataFrame\n",
    "df = pd.DataFrame({'x': x, 'Y': Y})\n",
    "\n",
    "# Specify and fit the model\n",
    "model_data_specification = smf.ols(\"Y ~ x\", data=df)\n",
    "fitted_model = model_data_specification.fit()\n",
    "\n",
    "# Output model summaries\n",
    "print(fitted_model.summary())  # Complete statistical summary\n",
    "print(fitted_model.summary().tables[1])  # Coefficients table\n",
    "print(fitted_model.params)  # Parameter estimates (intercept and slope)\n",
    "print(fitted_model.params.values)  # Parameter estimates as array\n",
    "print(fitted_model.rsquared)  # R-squared value\n",
    "\n",
    "# Visualization with plotly express\n",
    "df['Data'] = 'Data'  # Add column to legend\n",
    "fig = px.scatter(df, x='x', y='Y', color='Data', trendline='ols', title='Y vs. x')\n",
    "\n",
    "# Manual trendline for comparison\n",
    "fig.add_scatter(x=df['x'], y=fitted_model.fittedvalues, line=dict(color='blue'), name=\"trendline='ols'\")\n",
    "\n",
    "fig.show()  # Use fig.show(renderer=\"png\") for static environments like GitHub\n",
    "```\n",
    "\n",
    "### Explanation of Visualization Steps\n",
    "\n",
    "- `df['Data'] = 'Data'`: Adds a dummy column for color differentiation in the legend.\n",
    "- `trendline='ols'` in `px.scatter`: Automatically adds an OLS trendline based on the fitted model.\n",
    "- `fig.add_scatter`: Manually adds a line representing the fitted values for \\( Y \\) based on our `fitted_model`, showing the theoretical fit.\n",
    "\n",
    "The visualization shows the simulated data points and the fitted linear regression line, illustrating how well the model captures the linear relationship between \\( x \\) and \\( Y \\).\n",
    "https://chatgpt.com/share/672cb366-21c8-800d-b3e6-4dc37f39c529"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "870e2773",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '’' (U+2019) (3002060175.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    To visualize both the theoretical line from the initial model (Question 1) and the fitted line from the actual simulated data (Question 2), we can add the theoretical line on top of the scatter plot with the trendline. This lets us compare the nature of the two lines: one based purely on the model specification (theoretical) and the other on the actual sample data fit (fitted model). Here’s the code to do this:\u001b[0m\n\u001b[0m                                                                                                                                                                                                                                                                                                                                                                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '’' (U+2019)\n"
     ]
    }
   ],
   "source": [
    "To visualize both the theoretical line from the initial model (Question 1) and the fitted line from the actual simulated data (Question 2), we can add the theoretical line on top of the scatter plot with the trendline. This lets us compare the nature of the two lines: one based purely on the model specification (theoretical) and the other on the actual sample data fit (fitted model). Here’s the code to do this:\n",
    "\n",
    "```python\n",
    "# Append this to the code from Question 2\n",
    "\n",
    "# Define the range for x to plot the theoretical line\n",
    "x_range = np.array([df['x'].min(), df['x'].max()])\n",
    "\n",
    "# Calculate the theoretical line based on the initial parameters\n",
    "y_line = beta0 + beta1 * x_range\n",
    "fig.add_scatter(x=x_range, y=y_line, mode='lines',\n",
    "                name=f\"Theoretical Line: {beta0} + {beta1} * x\",\n",
    "                line=dict(dash='dot', color='orange'))\n",
    "\n",
    "fig.show()  # Use fig.show(renderer=\"png\") for static environments like GitHub\n",
    "```\n",
    "\n",
    "### Explanation of the Two Lines\n",
    "\n",
    "The figure now includes:\n",
    "1. **The Fitted Line (blue)**: This line results from fitting the simulated data to estimate the intercept and slope. Because it is based on a specific sample with random errors, it captures both the systematic part of the relationship and the variation in the sample data due to random sampling. \n",
    "\n",
    "2. **The Theoretical Line (dotted orange)**: This line reflects the true relationship according to the initial model specification (\\( Y = \\beta_0 + \\beta_1 x \\)), without any influence from sampling variation. It represents the \"ideal\" model under the chosen intercept and slope.\n",
    "\n",
    "### The Key Difference\n",
    "\n",
    "The purpose of comparing these lines is to illustrate **the impact of random sampling variation**. Each time we generate a new dataset from the theoretical model (by drawing new error terms), the fitted line will vary slightly from the theoretical line because of the random noise introduced in the sample. In contrast, the theoretical line remains fixed, as it represents the underlying relationship assumed in the model. Repeated simulations would show that the fitted line typically approximates the theoretical line but varies around it, capturing the concept of sampling variability in regression.\n",
    "https://chatgpt.com/share/672cb366-21c8-800d-b3e6-4dc37f39c529"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00908fd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (625349939.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    The `fitted_model.fittedvalues` are derived from the estimated parameters (intercept and slope) stored in `fitted_model.params` (or `fitted_model.params.values`). These values represent the best-fit line calculated by the Ordinary Least Squares (OLS) regression, which minimizes the sum of squared differences between the observed outcomes and the predicted values.\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "The `fitted_model.fittedvalues` are derived from the estimated parameters (intercept and slope) stored in `fitted_model.params` (or `fitted_model.params.values`). These values represent the best-fit line calculated by the Ordinary Least Squares (OLS) regression, which minimizes the sum of squared differences between the observed outcomes and the predicted values.\n",
    "\n",
    "### Derivation of `fitted_model.fittedvalues`\n",
    "\n",
    "For a linear regression model defined as:\n",
    "\n",
    "\\[\n",
    "Y = \\beta_0 + \\beta_1 x + \\epsilon\n",
    "\\]\n",
    "\n",
    "where:\n",
    "- \\( Y \\) is the outcome (dependent variable),\n",
    "- \\( x \\) is the predictor (independent variable),\n",
    "- \\( \\beta_0 \\) is the intercept, and\n",
    "- \\( \\beta_1 \\) is the slope.\n",
    "\n",
    "The estimated parameters, \\( \\hat{\\beta}_0 \\) and \\( \\hat{\\beta}_1 \\), are calculated by the regression process and stored in `fitted_model.params`.\n",
    "\n",
    "#### How `fitted_model.fittedvalues` Are Calculated\n",
    "\n",
    "Once we have \\( \\hat{\\beta}_0 \\) and \\( \\hat{\\beta}_1 \\) from `fitted_model.params`, the predicted or fitted values (\\( \\hat{Y} \\)) for each observation are calculated as:\n",
    "\n",
    "\\[\n",
    "\\hat{Y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x\n",
    "\\]\n",
    "\n",
    "In Python, this is equivalent to:\n",
    "\n",
    "```python\n",
    "fitted_values = fitted_model.params['Intercept'] + fitted_model.params['x'] * df['x']\n",
    "```\n",
    "\n",
    "Here’s the step-by-step process:\n",
    "\n",
    "1. `fitted_model.params` contains the estimated intercept and slope (e.g., `Intercept` and `x`).\n",
    "2. For each predictor value in `df['x']`, the fitted value (\\( \\hat{Y} \\)) is calculated using the formula above.\n",
    "3. The entire array of these predictions forms `fitted_model.fittedvalues`, which represents the expected values of \\( Y \\) based on the estimated model.\n",
    "\n",
    "### Connection to `fitted_model.summary().tables[1]`\n",
    "\n",
    "The table `fitted_model.summary().tables[1]` includes details about the estimated parameters:\n",
    "- **Estimate**: The estimated values of \\( \\hat{\\beta}_0 \\) and \\( \\hat{\\beta}_1 \\).\n",
    "- **Standard Error**: The standard error of each parameter estimate.\n",
    "- **t-value**: The t-statistic for each parameter, assessing the parameter’s statistical significance.\n",
    "- **P>|t|**: The p-value for the t-statistic, indicating whether each parameter is statistically significant.\n",
    "\n",
    "The estimates in this table (under the “Estimate” column) are exactly the values used in the formula above to compute `fitted_model.fittedvalues`. Thus, `fitted_model.fittedvalues` essentially applies the estimated intercept and slope across the predictor values in the dataset to generate the predicted outcomes.\n",
    "https://chatgpt.com/share/672cb366-21c8-800d-b3e6-4dc37f39c529"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84caee92",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1793510947.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    The line chosen for the fitted model using the \"ordinary least squares\" (OLS) method is the one that minimizes the sum of the squared differences between the observed values and the predicted values on the line. In other words, it minimizes the sum of squared residuals \\( (Y - \\hat{Y})^2 \\), where \\( Y \\) is the observed outcome and \\( \\hat{Y} \\) is the predicted value from the line.\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "The line chosen for the fitted model using the \"ordinary least squares\" (OLS) method is the one that minimizes the sum of the squared differences between the observed values and the predicted values on the line. In other words, it minimizes the sum of squared residuals \\( (Y - \\hat{Y})^2 \\), where \\( Y \\) is the observed outcome and \\( \\hat{Y} \\) is the predicted value from the line.\n",
    "\n",
    "The reason OLS uses \"squares\" is to ensure all residuals (differences) are positive, regardless of direction, and to give more weight to larger deviations. Squaring each residual penalizes larger errors more heavily, guiding the model to find a line that best fits all points with minimal total error. This approach is mathematically convenient and leads to a unique solution for the line that best approximates the observed data.\n",
    "https://chatgpt.com/share/672cb366-21c8-800d-b3e6-4dc37f39c529"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47192ed2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (813056584.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    In the context of a Simple Linear Regression model, each of these expressions captures a way of quantifying how well the model explains the variation in the outcome \\( Y \\). Let's break down the interpretation of each expression.\u001b[0m\n\u001b[0m                                                                                                                                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "In the context of a Simple Linear Regression model, each of these expressions captures a way of quantifying how well the model explains the variation in the outcome \\( Y \\). Let's break down the interpretation of each expression.\n",
    "\n",
    "### Expression 1: Proportion of Variation Explained by the Model\n",
    "\n",
    "The expression:\n",
    "\n",
    "\\[\n",
    "1 - \\frac{\\sum (Y - \\text{fitted\\_model.fittedvalues})^2}{\\sum (Y - Y.\\text{mean()})^2}\n",
    "\\]\n",
    "\n",
    "measures the proportion of the total variation in \\( Y \\) that is explained by the model. Here's why:\n",
    "\n",
    "- \\((Y - \\text{fitted\\_model.fittedvalues})^2\\) represents the **residual sum of squares** (RSS), which is the sum of squared differences between observed values and the values predicted by the model.\n",
    "- \\((Y - Y.\\text{mean()})^2\\) represents the **total sum of squares** (TSS), which is the sum of squared differences between observed values and the mean of \\( Y \\).\n",
    "\n",
    "The ratio \\(\\frac{\\text{RSS}}{\\text{TSS}}\\) gives the proportion of variation that is **not** explained by the model. Subtracting this from 1 gives the proportion of variation in \\( Y \\) that **is explained** by the model, meaning how much of the observed variability in \\( Y \\) the model accounts for. This is often referred to as the **coefficient of determination** or **\\( R^2 \\)**.\n",
    "\n",
    "### `fitted_model.rsquared`\n",
    "\n",
    "`fitted_model.rsquared` directly outputs the value of \\( R^2 \\), providing the same result as the first expression. It summarizes how well the model fits the data, where a higher \\( R^2 \\) value indicates a better fit (i.e., a larger proportion of the variation in \\( Y \\) is explained by the model). This makes \\( R^2 \\) a measure of the model's accuracy in capturing the relationship between the predictor and outcome.\n",
    "\n",
    "### `np.corrcoef(Y, fitted_model.fittedvalues)[0,1]**2`\n",
    "\n",
    "This expression calculates the squared correlation between \\( Y \\) and the model's predicted values (`fitted_model.fittedvalues`). The correlation coefficient (\\( r \\)) measures the linear association between two variables, and squaring it gives \\( r^2 \\), which is equivalent to \\( R^2 \\) in simple linear regression. This expression shows that the \\( R^2 \\) value is the square of the correlation between the observed outcomes and the model's predictions, reinforcing the idea that \\( R^2 \\) indicates the strength of the model's explanation of \\( Y \\)'s variation.\n",
    "\n",
    "### `np.corrcoef(Y, x)[0,1]**2`\n",
    "\n",
    "In a simple linear regression, this squared correlation coefficient between \\( Y \\) and the predictor \\( x \\) is also equivalent to \\( R^2 \\). This happens because, with only one predictor, the model essentially aims to capture the strength of the linear association between \\( Y \\) and \\( x \\). Hence, \\( \\text{np.corrcoef(Y, x)[0,1]}^2 \\) gives the same \\( R^2 \\) value as the expressions above, confirming the consistency and accuracy of the model in a single-predictor scenario. \n",
    "\n",
    "### Summary\n",
    "\n",
    "All four expressions quantify the proportion of variation in \\( Y \\) that is explained by the model, with each expression arriving at the same \\( R^2 \\) value in the case of a simple linear regression. \\( R^2 \\) thus serves as a concise measure of the model's explanatory power and accuracy, indicating the effectiveness of the predictor(s) in accounting for the outcome's variability.\n",
    "https://chatgpt.com/share/672cb366-21c8-800d-b3e6-4dc37f39c529"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1fd980e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 8) (1695043296.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    - **Assumption**: The residuals (differences between observed and predicted values) should follow a normal distribution with a mean of zero, indicating that the model's predictions are unbiased across the range of values.\u001b[0m\n\u001b[0m                                                                                                                                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 8)\n"
     ]
    }
   ],
   "source": [
    "The Simple Linear Regression model relies on several key assumptions, two of which do not appear fully compatible with the provided fertilizer and crop yield data:\n",
    "\n",
    "### 1. **Linearity**: \n",
    "   - **Assumption**: The relationship between the predictor (Amount of Fertilizer) and the outcome (Crop Yield) is assumed to be linear, meaning that changes in fertilizer use should result in proportional, consistent changes in crop yield.\n",
    "   - **Issue**: The scatter plot suggests a non-linear relationship between fertilizer and crop yield. Initially, crop yield increases relatively slowly, then sharply, and finally at a slower rate again. This pattern indicates that a single straight line may not adequately capture the relationship, as it seems more curved or exponential.\n",
    "\n",
    "### 2. **Normally Distributed Residuals**: \n",
    "   - **Assumption**: The residuals (differences between observed and predicted values) should follow a normal distribution with a mean of zero, indicating that the model's predictions are unbiased across the range of values.\n",
    "   - **Issue**: The histogram of residuals likely shows deviations from normality. If the residuals are not symmetrically distributed around zero, this suggests that the model consistently overestimates or underestimates yields in certain ranges, further indicating that a simple linear model might not be appropriate for capturing the true pattern in the data.\n",
    "\n",
    "### Summary\n",
    "\n",
    "These violations suggest that a **non-linear model** might be more suitable for this dataset, as it could better accommodate the changing rate of increase in crop yield as fertilizer use grows. A linear regression model may be overly simplistic and unable to capture the true underlying relationship, potentially leading to biased estimates and inaccurate predictions for crop yield.\n",
    "https://chatgpt.com/share/672cb366-21c8-800d-b3e6-4dc37f39c529"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3e8bf17",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1651638810.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    In the context of a Simple Linear Regression model, the null hypothesis of \"no linear association (on average)\" between the predictor (`waiting` time between eruptions) and the outcome (`duration` of eruptions) can be specified as follows:\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "### Null Hypothesis of No Linear Association\n",
    "\n",
    "In the context of a Simple Linear Regression model, the null hypothesis of \"no linear association (on average)\" between the predictor (`waiting` time between eruptions) and the outcome (`duration` of eruptions) can be specified as follows:\n",
    "\n",
    "\\[\n",
    "H_0: \\beta_1 = 0\n",
    "\\]\n",
    "\n",
    "where:\n",
    "- \\( \\beta_1 \\) is the slope of the regression line, representing the average change in `duration` for each additional unit of `waiting`.\n",
    "\n",
    "Under this null hypothesis, we assume there is no linear association between the waiting time and the duration of eruptions, implying that waiting time does not significantly impact eruption duration.\n",
    "\n",
    "### Analyzing the Evidence with the Old Faithful Geyser Dataset\n",
    "\n",
    "Using the provided code, we fit a linear regression model to the Old Faithful Geyser dataset:\n",
    "\n",
    "```python\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Load the Old Faithful Geyser dataset\n",
    "old_faithful = sns.load_dataset('geyser')\n",
    "\n",
    "# Specify and fit the model\n",
    "linear_for_specification = 'duration ~ waiting'\n",
    "model = smf.ols(linear_for_specification, data=old_faithful)\n",
    "fitted_model = model.fit()\n",
    "summary = fitted_model.summary()\n",
    "print(summary)\n",
    "```\n",
    "\n",
    "### Interpretation of Output\n",
    "\n",
    "The key elements to consider in the output are:\n",
    "\n",
    "1. **Coefficient for `waiting` (slope, \\( \\hat{\\beta}_1 \\))**:\n",
    "   - If the slope \\( \\hat{\\beta}_1 \\) is significantly different from zero, it would indicate evidence against the null hypothesis, suggesting that waiting time is linearly associated with eruption duration.\n",
    "\n",
    "2. **P-value**:\n",
    "   - The p-value associated with \\( \\hat{\\beta}_1 \\) tests the null hypothesis \\( H_0: \\beta_1 = 0 \\).\n",
    "   - If the p-value is low (typically below a significance level like 0.05), it indicates that we can reject the null hypothesis, concluding that there is a statistically significant linear relationship between waiting time and duration.\n",
    "\n",
    "3. **R-squared**:\n",
    "   - The \\( R^2 \\) value indicates the proportion of the variation in `duration` that is explained by the waiting time. A higher \\( R^2 \\) would suggest a stronger linear relationship.\n",
    "\n",
    "### Interpretation of Beliefs Regarding the Old Faithful Geyser Dataset\n",
    "\n",
    "If the p-value for \\( \\beta_1 \\) is low and the slope is significantly different from zero, we would have evidence to believe that there is a linear association between `waiting` and `duration`. This would imply that longer waiting times are associated with longer eruption durations. Conversely, if the p-value is high and \\( \\hat{\\beta}_1 \\) is close to zero, it would suggest that waiting time does not have a significant linear effect on eruption duration, leading us to maintain the null hypothesis.\n",
    "https://chatgpt.com/share/672cb366-21c8-800d-b3e6-4dc37f39c529"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5179f129",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (2684364173.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    To investigate whether a relationship between `duration` and `waiting` persists when the dataset is restricted to short wait times, we can examine the results of a linear regression for subsets of the data where `waiting` is less than 62, 64, and 66 minutes. Here's how we interpret the evidence against the null hypothesis in each restricted context:\u001b[0m\n\u001b[0m                                                                                                                                                                                                                                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "To investigate whether a relationship between `duration` and `waiting` persists when the dataset is restricted to short wait times, we can examine the results of a linear regression for subsets of the data where `waiting` is less than 62, 64, and 66 minutes. Here's how we interpret the evidence against the null hypothesis in each restricted context:\n",
    "\n",
    "### Steps and Interpretation\n",
    "\n",
    "1. **Restricting the Dataset to Short Wait Times**:\n",
    "   - We filter the data to include only rows where `waiting` is below each of the `short_wait_limit` values (62, 64, and 66) and fit a linear model to this subset.\n",
    "\n",
    "2. **Null Hypothesis for Each Subset**:\n",
    "   - For each restricted dataset, the null hypothesis remains:\n",
    "     \\[\n",
    "     H_0: \\beta_1 = 0\n",
    "     \\]\n",
    "   where \\( \\beta_1 \\) is the slope representing the relationship between `waiting` time and `duration`.\n",
    "\n",
    "3. **Examining Evidence Against the Null Hypothesis**:\n",
    "   - We focus on:\n",
    "     - **The p-value** for the `waiting` coefficient (\\( \\beta_1 \\)), which tests if the relationship is statistically significant.\n",
    "     - **The sign and magnitude of the `waiting` coefficient** (\\( \\beta_1 \\)), which indicates the direction and strength of the relationship.\n",
    "     - **R-squared value**, which measures the proportion of variation in `duration` explained by `waiting` in this restricted subset.\n",
    "\n",
    "4. **Interpreting the Results**:\n",
    "   - If the p-value is low (typically below 0.05), we would reject the null hypothesis, indicating that there is significant evidence of a linear relationship between `duration` and `waiting` for short wait times.\n",
    "   - If the p-value is high and the slope is close to zero, it would suggest no significant relationship within the short wait times.\n",
    "\n",
    "### Running the Code for Each Short Wait Limit\n",
    "\n",
    "Run the code below for each `short_wait_limit` value (62, 64, and 66) to generate the summary statistics and plots:\n",
    "\n",
    "```python\n",
    "import plotly.express as px\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Test for short wait times with limits 62, 64, and 66\n",
    "for short_wait_limit in [62, 64, 66]:\n",
    "    short_wait = old_faithful.waiting < short_wait_limit\n",
    "    # Perform OLS regression on restricted data\n",
    "    model_summary = smf.ols('duration ~ waiting', data=old_faithful[short_wait]).fit().summary().tables[1]\n",
    "    print(f\"Summary for short wait limit < {short_wait_limit}\")\n",
    "    print(model_summary)\n",
    "    \n",
    "    # Create scatter plot with OLS trendline\n",
    "    fig = px.scatter(old_faithful[short_wait], x='waiting', y='duration',\n",
    "                     title=f\"Old Faithful Geyser Eruptions for short wait times (<{short_wait_limit})\",\n",
    "                     trendline='ols')\n",
    "    fig.show()  # Use fig.show(renderer=\"png\") for static environments like GitHub\n",
    "```\n",
    "\n",
    "### Interpretation of Findings\n",
    "\n",
    "#### Expected Outcomes:\n",
    "1. **If p-values are consistently high**: This would suggest that within short wait times, there is no statistically significant linear relationship between `duration` and `waiting`, implying that `waiting` does not affect `duration` in this range.\n",
    "   \n",
    "2. **If p-values are low and the slope remains significant**: This would indicate that even within short wait times, there is a linear relationship between `waiting` and `duration`, albeit potentially weaker than in the full dataset. This might imply that the effect of `waiting` on `duration` is consistent but may vary in strength across different wait-time intervals.\n",
    "\n",
    "This approach allows us to assess whether the relationship between `duration` and `waiting` persists or weakens when focusing solely on shorter intervals. By examining each subset, we can determine how well the Simple Linear Regression model explains `duration` within restricted ranges, enhancing our understanding of geyser eruption behavior for shorter waits.\n",
    "https://chatgpt.com/share/672cb366-21c8-800d-b3e6-4dc37f39c529"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8fe954a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (710698780.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    In the context of long wait times, let's evaluate the relationship between `duration` and `waiting` for those eruptions where the waiting time exceeds 71 minutes. Here is an explanation of how to conduct the analysis, including coding steps to evaluate evidence against the null hypothesis and understand the nature of this relationship.\u001b[0m\n\u001b[0m                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "In the context of long wait times, let's evaluate the relationship between `duration` and `waiting` for those eruptions where the waiting time exceeds 71 minutes. Here is an explanation of how to conduct the analysis, including coding steps to evaluate evidence against the null hypothesis and understand the nature of this relationship.\n",
    "\n",
    "The given code filters the data for wait times greater than 71 minutes and performs a linear regression analysis using the OLS method. This allows us to examine whether there is a statistically significant relationship between waiting time and the duration of an eruption for these long wait times.\n",
    "\n",
    "Below, we'll expand the code to analyze the results and visualize the regression line.\n",
    "\n",
    "```python\n",
    "import plotly.express as px\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "\n",
    "# Define long wait times limit and filter the dataset\n",
    "long_wait_limit = 71\n",
    "long_wait = old_faithful.waiting > long_wait_limit\n",
    "\n",
    "# Fit a linear regression model using the filtered dataset\n",
    "fitted_model = smf.ols('duration ~ waiting', data=old_faithful[long_wait]).fit()\n",
    "\n",
    "# Print the summary table for the coefficient estimates\n",
    "print(\"Summary of Regression Model for Long Wait Times:\")\n",
    "print(fitted_model.summary().tables[1])\n",
    "\n",
    "# Create a scatter plot with a linear regression trendline\n",
    "fig = px.scatter(old_faithful[long_wait], x='waiting', y='duration', \n",
    "                 title=\"Old Faithful Geyser Eruptions for Long Wait Times (> \" + str(long_wait_limit) + \")\",\n",
    "                 trendline='ols')\n",
    "\n",
    "# Visualize the fitted line using the estimated slope and intercept from the model\n",
    "x_range = np.linspace(old_faithful[long_wait].waiting.min(), old_faithful[long_wait].waiting.max(), 100)\n",
    "y_line = fitted_model.params['Intercept'] + fitted_model.params['waiting'] * x_range\n",
    "fig.add_scatter(x=x_range, y=y_line, mode='lines', name='OLS Fitted Line', line=dict(color='blue'))\n",
    "\n",
    "# Show the plot\n",
    "fig.show()  # Use fig.show(renderer=\"png\") for GitHub and MarkUs Submissions\n",
    "```\n",
    "\n",
    "### Analysis and Interpretation\n",
    "\n",
    "1. **Summary Table (`fitted_model.summary().tables[1]`)**:\n",
    "   - This table provides information on the estimated coefficients (`Intercept` and `waiting`) along with their standard errors, t-statistics, and p-values.\n",
    "   - **Slope Coefficient (\\(\\hat{\\beta}_1\\))**: Look at the estimated value of the `waiting` coefficient to see if there is a significant linear relationship.\n",
    "   - **P-value**: A p-value lower than a significance level (e.g., 0.05) would indicate that there is significant evidence of a relationship between `waiting` and `duration` for long wait times.\n",
    "\n",
    "2. **Scatter Plot with Linear Regression Line**:\n",
    "   - **Scatter Plot**: Shows how the `duration` of eruptions is distributed against `waiting` times for eruptions with long wait times.\n",
    "   - **OLS Fitted Line**: The regression line is overlaid to visually depict the strength of the relationship.\n",
    "\n",
    "### Interpretation of Results\n",
    "\n",
    "- **Slope and Significance**:\n",
    "  - A positive and significant slope coefficient would imply that, for long wait times, there is an increasing relationship between the waiting time and the duration of the eruption. This would suggest that the longer the waiting time, the longer the subsequent eruption.\n",
    "  - If the p-value for the `waiting` coefficient is **small** (e.g., less than 0.05), we **reject the null hypothesis** of no linear relationship. This means that there is significant evidence that `waiting` is positively related to `duration` for long wait times.\n",
    "  - Conversely, a **high p-value** would indicate **no significant evidence** against the null hypothesis for these longer waits.\n",
    "\n",
    "- **Visual Interpretation**:\n",
    "  - The scatter plot allows us to see if the data points align well with the fitted line.\n",
    "  - A strong linear relationship would result in the data points closely following the fitted line, whereas a weak relationship would show more scatter.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "By examining the results for long wait times, we can understand whether the relationship between `waiting` and `duration` changes as we consider different subsets of the dataset. For longer waits, if the p-value is significant and the slope is positive, it implies that the relationship between waiting time and eruption duration is stronger and more pronounced compared to the full dataset or short waits. This difference helps us conclude whether different mechanisms may be influencing the behavior of geyser eruptions based on the amount of time between them.\n",
    "https://chatgpt.com/share/672cb366-21c8-800d-b3e6-4dc37f39c529"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3806b615",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '’' (U+2019) (1691779045.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[11], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    The question is exploring the use of an indicator variable (binary variable) in a linear regression model. Here’s a breakdown to help you understand and answer the question:\u001b[0m\n\u001b[0m                                                                                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '’' (U+2019)\n"
     ]
    }
   ],
   "source": [
    "The question is exploring the use of an indicator variable (binary variable) in a linear regression model. Here’s a breakdown to help you understand and answer the question:\n",
    "\n",
    "1. **Indicator Variable**: In this model specification, \\( Y_i = \\beta_{intercept} + 1_{[ \"long\" ]}(k_i) \\beta_{contrast} + \\epsilon_i \\), an indicator variable is used to differentiate between \"long\" and \"short\" wait times. Specifically, \\( 1_{[ \"long\" ]}(k_i) \\) equals 1 if the wait time is \"long\" and 0 if it's \"short\". This variable allows the model to separate the effect of \"long\" wait times from \"short\" wait times.\n",
    "\n",
    "2. **Comparison to Previous Models**: \n",
    "   - The previous models considered the variable `waiting` directly (as seen in models 1, 2, and 3), where `waiting` was treated as a continuous predictor of `duration`.\n",
    "   - In the new model specification with the indicator variable, we simplify the analysis by only distinguishing between two groups: \"short\" (under 68) and \"long\" (68 or more) wait times, rather than treating `waiting` as a continuous variable.\n",
    "\n",
    "3. **Big Picture Difference**:\n",
    "   - The previous models analyzed `waiting` as a continuous predictor, giving a specific slope to predict `duration` based on `waiting` time.\n",
    "   - The indicator variable model only considers if the wait time is “long” or “short,” thus only capturing the mean difference between the two groups. This is a simpler, categorical model compared to using a continuous predictor.\n",
    "\n",
    "4. **Null Hypothesis**:\n",
    "   - The null hypothesis in the indicator variable-based model would state that there is \"no difference in the average duration between the 'short' and 'long' wait groups.\"\n",
    "\n",
    "5. **Reporting Evidence**:\n",
    "   - To evaluate the evidence against the null hypothesis, you can use the results of a t-test on the coefficient for the indicator variable (`β_contrast`). A significant p-value would suggest a difference in average durations between \"short\" and \"long\" groups.\n",
    "\n",
    "In terms of interpretation:\n",
    "- If `β_contrast` is statistically significant, it indicates that \"long\" wait times are associated with different average durations compared to \"short\" wait times.\n",
    "- This model allows for a simpler understanding by focusing on categorical differences rather than continuous changes in wait time. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a81ad74a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (2377621535.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[12], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    The histograms of residuals provide insight into whether the assumption of normally distributed error terms holds for each of the fitted models. Let's go through each of the histograms to determine if the residuals resemble a normal distribution and understand why or why not.\u001b[0m\n\u001b[0m                                                                                                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "The histograms of residuals provide insight into whether the assumption of normally distributed error terms holds for each of the fitted models. Let's go through each of the histograms to determine if the residuals resemble a normal distribution and understand why or why not.\n",
    "\n",
    "### Evaluating the Histograms:\n",
    "\n",
    "1. **Model 1: All Data Using Slope**  \n",
    "   - **Description**: This model uses the entire dataset with a linear relationship between `duration` and `waiting`.\n",
    "   - **Histogram Analysis**:\n",
    "     - If the residuals are approximately symmetrically distributed around zero, have a bell-shaped appearance, and closely follow the overlaid normal distribution (black dashed line), then the residuals can be considered approximately normally distributed.\n",
    "     - **Conclusion**: The residuals may show a reasonable approximation of a normal distribution for Model 1 if the histogram closely matches the expected shape of the black dotted normal distribution curve.\n",
    "\n",
    "2. **Model 2: Short Wait Data**  \n",
    "   - **Description**: This model is restricted to short wait times (e.g., wait times less than 62, 64, or 66 minutes).\n",
    "   - **Histogram Analysis**:\n",
    "     - If the residuals have a skewed or multimodal distribution, they would not be consistent with the assumption of normality. \n",
    "     - Often, restricting data can lead to biased residuals, particularly if the restricted dataset does not contain the full variability seen in the full dataset.\n",
    "     - **Conclusion**: If the histogram for Model 2 is skewed or has multiple peaks, then it does **not** support the assumption of normally distributed residuals.\n",
    "\n",
    "3. **Model 3: Long Wait Data**  \n",
    "   - **Description**: This model includes only the data with long wait times (i.e., waiting times greater than 71 minutes).\n",
    "   - **Histogram Analysis**:\n",
    "     - The residuals could also exhibit non-normal patterns, such as skewness or outliers, particularly if the long wait times do not follow the same pattern as shorter wait times.\n",
    "     - **Conclusion**: If the histogram for Model 3 deviates substantially from the normal distribution (e.g., it is skewed or has heavy tails), then it does **not** support the normality assumption.\n",
    "\n",
    "4. **Model 4: All Data Using Indicator**  \n",
    "   - **Description**: This model uses a categorical indicator (`C(kind, Treatment(reference=\"short\"))`) rather than directly using `waiting`. It tries to explain differences in `duration` using a categorical variable distinguishing between short and long waits.\n",
    "   - **Histogram Analysis**:\n",
    "     - If the residuals display clear deviations from normality (e.g., multimodal patterns corresponding to different groups in the dataset), this suggests that the model does not fully capture the relationship between wait type and eruption duration.\n",
    "     - **Conclusion**: If the histogram for Model 4 is distinctly non-normal, likely due to the categorical nature of the predictor, it **does not** support the assumption of normally distributed residuals.\n",
    "\n",
    "### Determining Plausibility of the Assumption of Normality\n",
    "\n",
    "- **Which Histogram Suggests Plausibility**: \n",
    "  - The histogram that **best approximates a symmetric bell-shaped curve** closely aligning with the overlaid black dashed normal distribution line suggests the plausibility of normally distributed residuals. Typically, this would be the histogram for **Model 1** (the full dataset), as it uses all available data, which often helps the residuals to approximate normality.\n",
    "\n",
    "- **Why the Other Three Do Not Support the Assumption**:\n",
    "  1. **Model 2 (Short Wait Data)**: The restriction to short waits may cause **reduced variability** and introduce **skewness**, as it does not encompass the full range of data.\n",
    "  2. **Model 3 (Long Wait Data)**: The restriction to long waits may cause **non-linear relationships** or result in **skewed residuals** due to the specific nature of longer waits affecting the duration in a non-uniform manner.\n",
    "  3. **Model 4 (Categorical Indicator)**: The use of a categorical variable (`kind`) may lead to **distinct group effects**, resulting in a residual distribution that is **not unimodal** and **not symmetric**. This often leads to multimodal distributions in the residuals.\n",
    "\n",
    "In conclusion, the residuals from Model 1 are most likely to be approximately normally distributed, given the entire dataset is used to estimate the relationship, allowing the model to capture the general trend without biases from restricted data. The other models, either due to dataset restriction or the nature of the predictor, tend to violate the normality assumption.\n",
    "https://chatgpt.com/share/672cb366-21c8-800d-b3e6-4dc37f39c529"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0352462",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '—' (U+2014) (3677528316.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[13], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    This question involves comparing two different statistical approaches — permutation testing and bootstrapping — to assess whether there's a significant difference in durations between two groups, \"short\" and \"long\" wait times. Here’s how each part can be approached:\u001b[0m\n\u001b[0m                                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '—' (U+2014)\n"
     ]
    }
   ],
   "source": [
    "This question involves comparing two different statistical approaches — permutation testing and bootstrapping — to assess whether there's a significant difference in durations between two groups, \"short\" and \"long\" wait times. Here’s how each part can be approached:\n",
    "\n",
    "### (A) Permutation Test\n",
    "\n",
    "In a permutation test, we want to test the null hypothesis:\n",
    "\n",
    "\\[\n",
    "H_0: \\mu_{\\text{short}} = \\mu_{\\text{long}}\n",
    "\\]\n",
    "\n",
    "The steps are:\n",
    "1. Combine the \"short\" and \"long\" data into a single dataset.\n",
    "2. Shuffle the labels of \"short\" and \"long\" groups randomly and separate the data back into two groups of the same sizes as the original \"short\" and \"long\" groups.\n",
    "3. Calculate the difference in means between the two new shuffled groups.\n",
    "4. Repeat steps 2 and 3 many times (e.g., 10,000 permutations) to create a distribution of mean differences under the null hypothesis.\n",
    "5. Compare the actual observed difference in means to this distribution. If the observed difference is in the tails (e.g., extreme 5%), we may reject \\( H_0 \\), suggesting a significant difference.\n",
    "\n",
    "### (B) Bootstrap Confidence Interval\n",
    "\n",
    "To construct a 95% bootstrap confidence interval for the difference in means between \"short\" and \"long\":\n",
    "1. Resample (with replacement) within each group (\"short\" and \"long\") separately, many times (e.g., 10,000 resamples).\n",
    "2. For each resample, calculate the difference in means between the \"short\" and \"long\" groups.\n",
    "3. Store these differences and, after repeating, generate a distribution of mean differences.\n",
    "4. Use the 2.5th and 97.5th percentiles of this distribution (using `np.quantile`) to construct a 95% confidence interval.\n",
    "\n",
    "### (a) Explanation of Sampling Approaches\n",
    "\n",
    "- **Permutation Test**: The permutation test assumes that under the null hypothesis, the labels \"short\" and \"long\" are exchangeable because there’s no inherent difference between the groups. By shuffling labels, we simulate the scenario where the group assignment doesn’t matter, building a distribution of differences under the null.\n",
    "  \n",
    "- **Bootstrap**: The bootstrap approach resamples within each group independently, assuming each sample represents the population it came from. This allows for estimation of the sampling variability in the observed mean difference.\n",
    "\n",
    "### (b) Comparison with Indicator Variable Approach\n",
    "\n",
    "The indicator variable approach typically involves using a regression model where an indicator (dummy) variable represents group membership (e.g., 0 for \"short\" and 1 for \"long\"). In such models:\n",
    "- **Similarity**: Like the permutation and bootstrap tests, it tests for differences between groups. If the coefficient on the indicator variable is significantly different from zero, it suggests a difference between \"short\" and \"long\".\n",
    "- **Difference**: The indicator variable model is a parametric approach that assumes a certain form for the relationship (linear regression), while permutation and bootstrap are non-parametric, relying on resampling techniques without assuming a specific distribution.\n",
    "\n",
    "These different methods offer robustness in testing group differences, with the permutation and bootstrap methods providing flexibility when distributional assumptions of parametric tests may not hold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f3fd72",
   "metadata": {},
   "source": [
    "yes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
